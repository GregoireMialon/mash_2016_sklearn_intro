{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to deep learning using Keras\n",
    "\n",
    "In this class we will explore some of the deep learning capabilities of the library Keras. After this class, you will be able to:\n",
    "\n",
    "  * Build and train a simple model using this library.\n",
    "  * Use data augmentation to generate \"fake\" samples and improve accuracy of a deep learning model with limited training data.\n",
    "  * Standing on the shoulders of giants: use a pretrained network to improve accuracy for:\n",
    "    - image classification\n",
    "    - natural language processing.\n",
    "\n",
    "\n",
    "## First steps with keras\n",
    "\n",
    "First, we will install Keras. If you don't have keras installed, executing the following line will install it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching package metadata .........\n",
      "Solving package specifications: ..........\n",
      "\n",
      "# All requested packages already installed.\n",
      "# packages in environment at /Users/fabianpedregosa/anaconda3:\n",
      "#\n",
      "keras                     1.0.7                    py35_0    conda-forge\n",
      "tensorflow                0.12.1                   py35_1    conda-forge\n"
     ]
    }
   ],
   "source": [
    "!conda install --yes --channel https://conda.anaconda.org/conda-forge keras tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First steps with Keras\n",
    "\n",
    "Keras is a high-level library for deep learning with an API modeled after scikit-learn. It makes use of Theano of Tensorflow beneath the scenes for the actual computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API has two modes, Sequential and Functional. We will focus on the Sequential API. \n",
    "\n",
    "This API is based on the ```Sequential``` object, to which we add the different layers of the network. We will start with a simple shallow networks, a single-layer perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_1 (Dense)                  (None, 1)             5           dense_input_1[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 5\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# generate dummy data\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = (iris.target >= 1).astype(int)  # take only two classes for simplicity\n",
    "n_features = iris.data.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=n_features, activation='sigmoid'))\n",
    "\n",
    "# model.summary prints a description of your model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train the model on the dummy generated data.\n",
    "\n",
    "<img style=\"float: left; width: 50px; top: -20px\" src=\"https://cdn1.iconfinder.com/data/icons/hawcons/32/700303-icon-61-warning-128.png\" /> In Keras, before a model is fitted it needs to be \"compiled\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "150/150 [==============================] - 0s - loss: 1.4182 - acc: 0.6667     \n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 0s - loss: 1.3883 - acc: 0.6667     \n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 0s - loss: 1.3659 - acc: 0.6667     \n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 0s - loss: 1.3458 - acc: 0.6667     \n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 0s - loss: 1.3268 - acc: 0.6667     \n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 0s - loss: 1.3086 - acc: 0.6667     \n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 0s - loss: 1.2905 - acc: 0.6667     \n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 0s - loss: 1.2735 - acc: 0.6667     \n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 0s - loss: 1.2562 - acc: 0.6667     \n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 0s - loss: 1.2384 - acc: 0.6667     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x113080f60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model, iterating on the data in batches\n",
    "# of 32 samples\n",
    "model.fit(X, y, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 32/150 [=====>........................] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2275867201387882, 0.66666666666666663]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the score can be computed using model.evaluate\n",
    "model.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn <=> Keras dictionary\n",
    "\n",
    "```model.fit```  <-> ```model.compile``` followed by ```model.fit```\n",
    "\n",
    "```model.predict``` <-> ```model.predict```\n",
    "\n",
    "```model.score``` <-> ```model.evaluate(x)[1]```\n",
    "\n",
    "---\n",
    "\n",
    "## Going deeper\n",
    "\n",
    "The great aspect of Keras is that it makes it easier to build more complex models by adding layers to the network. This is achieved e.g. with the ```.add``` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_14 (Dense)                 (None, 64)            320         dense_input_7[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 64)            0           dense_14[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_15 (Dense)                 (None, 64)            4160        dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 64)            0           dense_15[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_16 (Dense)                 (None, 1)             65          dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 4545\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=n_features, init='uniform', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "150/150 [==============================] - 0s - loss: 0.6451 - acc: 0.6200     \n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 0s - loss: 0.5834 - acc: 0.7067     \n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 0s - loss: 0.5490 - acc: 0.6733     \n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 0s - loss: 0.5192 - acc: 0.6800     \n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 0s - loss: 0.5182 - acc: 0.6933     \n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 0s - loss: 0.4748 - acc: 0.7267     \n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 0s - loss: 0.4320 - acc: 0.7667     \n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 0s - loss: 0.4002 - acc: 0.8200     \n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 0s - loss: 0.3934 - acc: 0.8133     \n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 0s - loss: 0.3764 - acc: 0.8467     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x114be8978>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model, iterating on the data in batches\n",
    "# of 32 samples\n",
    "model.fit(X, y, nb_epoch=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 32/150 [=====>........................] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27751764804124834, 1.0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, it performs better on the train set since the model is more complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning on images\n",
    "\n",
    "Now lets turn to a real example, discriminating between dogs or cats in natural images:\n",
    "\n",
    "![](https://blog.keras.io/img/imgclf/cats_and_dogs.png)\n",
    "\n",
    "For this, I have prepared a dataset consisting of 1000 cats and 1000 dogs that you can [download from here](https://www.dropbox.com/s/p0vsabq3og88702/cats_vs_dogs.zip?dl=0). You should extract it to the current directory (i.e. wherever this notebook lives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 400 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of '$dataset/train'\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'cats_vs_dogs/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=32,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'cats_vs_dogs/test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(3, 150, 150)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# the model so far outputs 3D feature maps (height, width, features)\n",
    "# On top of it we stick two fully-connected layers. We end the model with a single unit and a sigmoid activation, \n",
    "# which is perfect for a binary classification. To go with it we will also use the binary_crossentropy\n",
    "# loss to train our model.\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 96s - loss: 0.0940 - acc: 0.9675 - val_loss: 1.4157 - val_acc: 0.6741\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 92s - loss: 0.1019 - acc: 0.9630 - val_loss: 1.2716 - val_acc: 0.7500\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 96s - loss: 0.0931 - acc: 0.9665 - val_loss: 1.4749 - val_acc: 0.6964\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 104s - loss: 0.0846 - acc: 0.9680 - val_loss: 1.1878 - val_acc: 0.7163\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 94s - loss: 0.0897 - acc: 0.9665 - val_loss: 1.6965 - val_acc: 0.6587\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 92s - loss: 0.0626 - acc: 0.9725 - val_loss: 1.5452 - val_acc: 0.7009\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 93s - loss: 0.0667 - acc: 0.9770 - val_loss: 2.0394 - val_acc: 0.6827\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 91s - loss: 0.0759 - acc: 0.9760 - val_loss: 1.6437 - val_acc: 0.7188\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 92s - loss: 0.0592 - acc: 0.9755 - val_loss: 1.8499 - val_acc: 0.7009\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 92s - loss: 0.0507 - acc: 0.9795 - val_loss: 2.0522 - val_acc: 0.6538\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 87s - loss: 0.0551 - acc: 0.9835 - val_loss: 2.0183 - val_acc: 0.7009\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 83s - loss: 0.0570 - acc: 0.9785 - val_loss: 1.7277 - val_acc: 0.7308\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 84s - loss: 0.0746 - acc: 0.9780 - val_loss: 1.5204 - val_acc: 0.6587\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 85s - loss: 0.0625 - acc: 0.9775 - val_loss: 2.3565 - val_acc: 0.6652\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 87s - loss: 0.0575 - acc: 0.9825 - val_loss: 1.0225 - val_acc: 0.7452\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 87s - loss: 0.0436 - acc: 0.9840 - val_loss: 2.5118 - val_acc: 0.6741\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 87s - loss: 0.0799 - acc: 0.9805 - val_loss: 1.9552 - val_acc: 0.7212\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 84s - loss: 0.0442 - acc: 0.9860 - val_loss: 2.5431 - val_acc: 0.6971\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 88s - loss: 0.0654 - acc: 0.9805 - val_loss: 2.1729 - val_acc: 0.7009\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 90s - loss: 0.0489 - acc: 0.9830 - val_loss: 1.8390 - val_acc: 0.7260\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=2000,\n",
    "        nb_epoch=20,\n",
    "        validation_data=test_generator,\n",
    "        nb_val_samples=200\n",
    ")\n",
    "model.save_weights('first_try.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Problem 1:\n",
    "\n",
    "  * What is going on? This architecture achives above 90% accuracy on Imagenet -- a much more challenging task.\n",
    "  * How can we solve this issue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pretrained networks\n",
    "\n",
    "Another way to leaverage similarity with existing datasets is through pretrained networks. Such a network would have already learned features that are useful for most computer vision problems, and leveraging such features would allow us to reach a better accuracy than any method that would only rely on the available data.\n",
    "\n",
    "# Problem 2\n",
    "\n",
    "Use a pre-trained networks to generate the appropriate features for this task. For this, we will:\n",
    "\n",
    " * [Download the weights](https://drive.google.com/file/d/0Bz7KyqmuGsilT0J5dmRCM0ROVHc/view?usp=sharing) of an existing model, more precisely a 16-layer network used by the VGG team in the ILSVRC-2014 competition.\n",
    " \n",
    " * The code below will generate the features for the train set and save it to the file ```bottleneck_features_train.npy``` and ```bottleneck_features_test.npy```.\n",
    "\n",
    "People have posted pretrained networks https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# template code \n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "# path to the model weights file.\n",
    "weights_path = 'vgg16_weights.h5'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'cats_vs_dogs/train'\n",
    "validation_data_dir = 'cats_vs_dogs/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "nb_epoch = 50\n",
    "\n",
    "\n",
    "def save_bottlebeck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(3, img_width, img_height)))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # load the weights of the VGG16 networks\n",
    "    # (trained on ImageNet, won the ILSVRC competition in 2014)\n",
    "    # note: when there is a complete match between your model definition\n",
    "    # and your weight savefile, you can simply call model.load_weights(filename)\n",
    "    assert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\" variable in script).'\n",
    "    f = h5py.File(weights_path)\n",
    "    for k in range(f.attrs['nb_layers']):\n",
    "        if k >= len(model.layers):\n",
    "            # we don't look at the last (fully-connected) layers in the savefile\n",
    "            break\n",
    "        g = f['layer_{}'.format(k)]\n",
    "        weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "        model.layers[k].set_weights(weights)\n",
    "    f.close()\n",
    "    print('Model loaded.')\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "            train_data_dir,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=32,\n",
    "            class_mode=None,\n",
    "            shuffle=False)\n",
    "    bottleneck_features_train = model.predict_generator(generator, nb_train_samples)\n",
    "    np.save(open('bottleneck_features_train.npy', 'w'), bottleneck_features_train)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "            validation_data_dir,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=32,\n",
    "            class_mode=None,\n",
    "            shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(generator, nb_validation_samples)\n",
    "    np.save(open('bottleneck_features_test.npy', 'w'), bottleneck_features_validation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
